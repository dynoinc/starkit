// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: queries.sql

package ragstore

import (
	"context"

	"github.com/jackc/pgx/v5/pgtype"
	pgvector_go "github.com/pgvector/pgvector-go"
)

const createEmbeddingModel = `-- name: CreateEmbeddingModel :one
INSERT INTO embedding_models (name, dimensions) 
VALUES ($1, $2) 
ON CONFLICT (name) DO UPDATE
SET dimensions = EXCLUDED.dimensions
RETURNING id
`

type CreateEmbeddingModelParams struct {
	Name       string `json:"name"`
	Dimensions int32  `json:"dimensions"`
}

func (q *Queries) CreateEmbeddingModel(ctx context.Context, arg CreateEmbeddingModelParams) (int32, error) {
	row := q.db.QueryRow(ctx, createEmbeddingModel, arg.Name, arg.Dimensions)
	var id int32
	err := row.Scan(&id)
	return id, err
}

const deleteChunksByDocumentID = `-- name: DeleteChunksByDocumentID :exec
DELETE FROM chunks 
WHERE document_id = $1
`

// Chunk operations
func (q *Queries) DeleteChunksByDocumentID(ctx context.Context, documentID int32) error {
	_, err := q.db.Exec(ctx, deleteChunksByDocumentID, documentID)
	return err
}

const deleteDocument = `-- name: DeleteDocument :exec
DELETE FROM documents 
WHERE external_id = $1
`

func (q *Queries) DeleteDocument(ctx context.Context, externalID string) error {
	_, err := q.db.Exec(ctx, deleteDocument, externalID)
	return err
}

const deleteDocumentsByKindPrefix = `-- name: DeleteDocumentsByKindPrefix :execrows
DELETE FROM documents
WHERE kind LIKE $1::text || '%'
`

func (q *Queries) DeleteDocumentsByKindPrefix(ctx context.Context, dollar_1 string) (int64, error) {
	result, err := q.db.Exec(ctx, deleteDocumentsByKindPrefix, dollar_1)
	if err != nil {
		return 0, err
	}
	return result.RowsAffected(), nil
}

const getAllChunksForDocID = `-- name: GetAllChunksForDocID :many
SELECT chunk_text 
FROM chunks 
WHERE document_id = $1 
ORDER BY chunk_index ASC
`

func (q *Queries) GetAllChunksForDocID(ctx context.Context, documentID int32) ([]string, error) {
	rows, err := q.db.Query(ctx, getAllChunksForDocID, documentID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []string{}
	for rows.Next() {
		var chunk_text string
		if err := rows.Scan(&chunk_text); err != nil {
			return nil, err
		}
		items = append(items, chunk_text)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getDocument = `-- name: GetDocument :one
SELECT external_id, source, kind, content_type, attributes, body, updated_at 
FROM documents 
WHERE external_id = $1
`

type GetDocumentRow struct {
	ExternalID  string           `json:"external_id"`
	Source      string           `json:"source"`
	Kind        string           `json:"kind"`
	ContentType string           `json:"content_type"`
	Attributes  []byte           `json:"attributes"`
	Body        string           `json:"body"`
	UpdatedAt   pgtype.Timestamp `json:"updated_at"`
}

func (q *Queries) GetDocument(ctx context.Context, externalID string) (GetDocumentRow, error) {
	row := q.db.QueryRow(ctx, getDocument, externalID)
	var i GetDocumentRow
	err := row.Scan(
		&i.ExternalID,
		&i.Source,
		&i.Kind,
		&i.ContentType,
		&i.Attributes,
		&i.Body,
		&i.UpdatedAt,
	)
	return i, err
}

const getDocumentIDByExternalID = `-- name: GetDocumentIDByExternalID :one
SELECT id 
FROM documents 
WHERE external_id = $1
`

func (q *Queries) GetDocumentIDByExternalID(ctx context.Context, externalID string) (int32, error) {
	row := q.db.QueryRow(ctx, getDocumentIDByExternalID, externalID)
	var id int32
	err := row.Scan(&id)
	return id, err
}

const getDocuments = `-- name: GetDocuments :many
SELECT external_id, source, kind, content_type, attributes, body, updated_at
FROM documents
WHERE ($1::text IS NULL OR kind LIKE $1::text || '%')
    AND ($2::jsonb IS NULL OR attributes @> $2::jsonb)
ORDER BY updated_at DESC
LIMIT $3::int
`

type GetDocumentsParams struct {
	KindPrefix   string `json:"kind_prefix"`
	FiltersJsonb []byte `json:"filters_jsonb"`
	LimitCount   int32  `json:"limit_count"`
}

type GetDocumentsRow struct {
	ExternalID  string           `json:"external_id"`
	Source      string           `json:"source"`
	Kind        string           `json:"kind"`
	ContentType string           `json:"content_type"`
	Attributes  []byte           `json:"attributes"`
	Body        string           `json:"body"`
	UpdatedAt   pgtype.Timestamp `json:"updated_at"`
}

func (q *Queries) GetDocuments(ctx context.Context, arg GetDocumentsParams) ([]GetDocumentsRow, error) {
	rows, err := q.db.Query(ctx, getDocuments, arg.KindPrefix, arg.FiltersJsonb, arg.LimitCount)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []GetDocumentsRow{}
	for rows.Next() {
		var i GetDocumentsRow
		if err := rows.Scan(
			&i.ExternalID,
			&i.Source,
			&i.Kind,
			&i.ContentType,
			&i.Attributes,
			&i.Body,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getEmbeddingModel = `-- name: GetEmbeddingModel :one
SELECT id, name, dimensions 
FROM embedding_models 
WHERE name = $1
`

type GetEmbeddingModelRow struct {
	ID         int32  `json:"id"`
	Name       string `json:"name"`
	Dimensions int32  `json:"dimensions"`
}

// Embedding model operations
func (q *Queries) GetEmbeddingModel(ctx context.Context, name string) (GetEmbeddingModelRow, error) {
	row := q.db.QueryRow(ctx, getEmbeddingModel, name)
	var i GetEmbeddingModelRow
	err := row.Scan(&i.ID, &i.Name, &i.Dimensions)
	return i, err
}

const insertChunk = `-- name: InsertChunk :exec
INSERT INTO chunks (document_id, chunk_index, chunk_text) 
VALUES ($1, $2, $3)
`

type InsertChunkParams struct {
	DocumentID int32  `json:"document_id"`
	ChunkIndex int32  `json:"chunk_index"`
	ChunkText  string `json:"chunk_text"`
}

func (q *Queries) InsertChunk(ctx context.Context, arg InsertChunkParams) error {
	_, err := q.db.Exec(ctx, insertChunk, arg.DocumentID, arg.ChunkIndex, arg.ChunkText)
	return err
}

const insertChunkWithEmbedding = `-- name: InsertChunkWithEmbedding :exec
INSERT INTO chunks (document_id, chunk_index, embedding_model_id, chunk_text, embedding) 
VALUES ($1, $2, $3, $4, $5)
`

type InsertChunkWithEmbeddingParams struct {
	DocumentID       int32              `json:"document_id"`
	ChunkIndex       int32              `json:"chunk_index"`
	EmbeddingModelID pgtype.Int4        `json:"embedding_model_id"`
	ChunkText        string             `json:"chunk_text"`
	Embedding        pgvector_go.Vector `json:"embedding"`
}

func (q *Queries) InsertChunkWithEmbedding(ctx context.Context, arg InsertChunkWithEmbeddingParams) error {
	_, err := q.db.Exec(ctx, insertChunkWithEmbedding,
		arg.DocumentID,
		arg.ChunkIndex,
		arg.EmbeddingModelID,
		arg.ChunkText,
		arg.Embedding,
	)
	return err
}

const lexicalSearch = `-- name: LexicalSearch :many
SELECT
    d.external_id,
    c.chunk_text,
    c.chunk_index,
    ts_rank(to_tsvector('english', c.chunk_text), plainto_tsquery('english', $1)) as score,
    d.updated_at,
    d.source,
    d.kind,
    d.attributes
FROM chunks c
JOIN documents d ON c.document_id = d.id
WHERE to_tsvector('english', c.chunk_text) @@ plainto_tsquery('english', $1)
    AND ($2::text IS NULL OR d.kind LIKE $2::text || '%')
    AND ($3::jsonb IS NULL OR d.attributes @> $3::jsonb)
ORDER BY
    ts_rank(to_tsvector('english', c.chunk_text), plainto_tsquery('english', $1)) DESC
LIMIT $4::int
`

type LexicalSearchParams struct {
	KeywordQuery string `json:"keyword_query"`
	KindPrefix   string `json:"kind_prefix"`
	FiltersJsonb []byte `json:"filters_jsonb"`
	LimitCount   int32  `json:"limit_count"`
}

type LexicalSearchRow struct {
	ExternalID string           `json:"external_id"`
	ChunkText  string           `json:"chunk_text"`
	ChunkIndex int32            `json:"chunk_index"`
	Score      float32          `json:"score"`
	UpdatedAt  pgtype.Timestamp `json:"updated_at"`
	Source     string           `json:"source"`
	Kind       string           `json:"kind"`
	Attributes []byte           `json:"attributes"`
}

// Search operations
func (q *Queries) LexicalSearch(ctx context.Context, arg LexicalSearchParams) ([]LexicalSearchRow, error) {
	rows, err := q.db.Query(ctx, lexicalSearch,
		arg.KeywordQuery,
		arg.KindPrefix,
		arg.FiltersJsonb,
		arg.LimitCount,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []LexicalSearchRow{}
	for rows.Next() {
		var i LexicalSearchRow
		if err := rows.Scan(
			&i.ExternalID,
			&i.ChunkText,
			&i.ChunkIndex,
			&i.Score,
			&i.UpdatedAt,
			&i.Source,
			&i.Kind,
			&i.Attributes,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const semanticSearch = `-- name: SemanticSearch :many
SELECT
    d.external_id,
    c.chunk_text,
    c.chunk_index,
    c.embedding <-> $1 as score,
    d.updated_at,
    d.source,
    d.kind,
    d.attributes
FROM chunks c
JOIN documents d ON c.document_id = d.id
WHERE c.embedding IS NOT NULL
    AND ($2::text IS NULL OR d.kind LIKE $2::text || '%')
    AND ($3::jsonb IS NULL OR d.attributes @> $3::jsonb)
ORDER BY (c.embedding <-> $1) DESC
LIMIT $4::int
`

type SemanticSearchParams struct {
	Embedding    pgvector_go.Vector `json:"embedding"`
	KindPrefix   string             `json:"kind_prefix"`
	FiltersJsonb []byte             `json:"filters_jsonb"`
	LimitCount   int32              `json:"limit_count"`
}

type SemanticSearchRow struct {
	ExternalID string           `json:"external_id"`
	ChunkText  string           `json:"chunk_text"`
	ChunkIndex int32            `json:"chunk_index"`
	Score      interface{}      `json:"score"`
	UpdatedAt  pgtype.Timestamp `json:"updated_at"`
	Source     string           `json:"source"`
	Kind       string           `json:"kind"`
	Attributes []byte           `json:"attributes"`
}

func (q *Queries) SemanticSearch(ctx context.Context, arg SemanticSearchParams) ([]SemanticSearchRow, error) {
	rows, err := q.db.Query(ctx, semanticSearch,
		arg.Embedding,
		arg.KindPrefix,
		arg.FiltersJsonb,
		arg.LimitCount,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []SemanticSearchRow{}
	for rows.Next() {
		var i SemanticSearchRow
		if err := rows.Scan(
			&i.ExternalID,
			&i.ChunkText,
			&i.ChunkIndex,
			&i.Score,
			&i.UpdatedAt,
			&i.Source,
			&i.Kind,
			&i.Attributes,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const upsertDocument = `-- name: UpsertDocument :one
INSERT INTO documents (external_id, source, kind, content_type, attributes, body, updated_at)
VALUES ($1, $2, $3, $4, $5, $6, $7)
ON CONFLICT (external_id) DO UPDATE
SET
    source = EXCLUDED.source,
    kind = EXCLUDED.kind,
    content_type = EXCLUDED.content_type,
    attributes = EXCLUDED.attributes,
    body = EXCLUDED.body,
    updated_at = EXCLUDED.updated_at
RETURNING id
`

type UpsertDocumentParams struct {
	ExternalID  string           `json:"external_id"`
	Source      string           `json:"source"`
	Kind        string           `json:"kind"`
	ContentType string           `json:"content_type"`
	Attributes  []byte           `json:"attributes"`
	Body        string           `json:"body"`
	UpdatedAt   pgtype.Timestamp `json:"updated_at"`
}

// Document operations
func (q *Queries) UpsertDocument(ctx context.Context, arg UpsertDocumentParams) (int32, error) {
	row := q.db.QueryRow(ctx, upsertDocument,
		arg.ExternalID,
		arg.Source,
		arg.Kind,
		arg.ContentType,
		arg.Attributes,
		arg.Body,
		arg.UpdatedAt,
	)
	var id int32
	err := row.Scan(&id)
	return id, err
}
